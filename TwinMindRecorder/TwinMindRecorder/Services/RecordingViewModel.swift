//
//  RecordingViewModel.swift
//  TwinMindRecorder
//
//  Created by Jerry Zhang on 2025-07-02.
//

import Foundation
import AVFoundation
import SwiftData
import AVFAudio
import UIKit

/// Handles all audio recording functionality using AVAudioEngine
@MainActor
class RecordingViewModel: ObservableObject {
    // MARK: - Published Properties (for UI updates)
    @Published var isRecording = false
    @Published var currentSession: RecordingSession?
    @Published var recordingDuration: TimeInterval = 0
    @Published var audioLevel: Float = 0.0
    @Published var hasPermission = false
    
    @Published var hasLowStorage = false
    private var selectedQuality: AudioQuality = .medium

    
    // MARK: - Audio Engine Components
    private var audioEngine = AVAudioEngine()
    private var audioFile: AVAudioFile?
    private var recordingTimer: Timer?
    private var segmentTimer: Timer?
    
    // MARK: - Recording Configuration
    @Published var segmentDuration: TimeInterval = 30.0
    
    private var currentSegmentStartTime: TimeInterval = 0
    private var segments: [AudioSegment] = []
    
    
    // MARK: - Model Context (for saving to database)
    private var modelContext: ModelContext?
    
    // Add Transcription Service
    private let transcriptionService = AudioTranscriptionService()

    
    init() {
        setupAudioSession()
        setupAudioSessionObservers()
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAppWillResignActive),
            name: UIApplication.willResignActiveNotification,
            object: nil
        )

        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAppDidBecomeActive),
            name: UIApplication.didBecomeActiveNotification,
            object: nil
        )

    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    /// Configure the audio session for recording
    private func setupAudioSession() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            
            try audioSession.setCategory(.playAndRecord,
                                         mode: .default,
                                         options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP])
            
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)

            // Request mic permission
            audioSession.requestRecordPermission { [weak self] allowed in
                DispatchQueue.main.async {
                    self?.hasPermission = allowed
                    if !allowed {
                        print("Microphone permission denied")
                    }
                }
            }
            
        } catch {
            print("âŒ Failed to setup audio session: \(error)")
        }
    }
}

// MARK: - Recording Controls
extension RecordingViewModel {
    func hasSufficientStorage(minimumBytes: Int64 = 100 * 1024 * 1024) -> Bool {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!

        do {
            let values = try documentsPath.resourceValues(forKeys: [.volumeAvailableCapacityForImportantUsageKey])
            let available = values.volumeAvailableCapacityForImportantUsage ?? 0
            let availableMB = Double(available) / (1024 * 1024)
            print("ðŸ“¦ Available space: \(availableMB.rounded()) MB")
            
            return available > minimumBytes
            
        } catch {
            print("âŒ Failed to check available storage: \(error)")
            return true // Assume yes, to not block recording
        }
    }

    
    /// Start a new recording session
    func startRecording(title: String? = nil, modelContext: ModelContext, quality: AudioQuality = .medium) {
        guard !isRecording else { return }
        
        guard hasSufficientStorage() else {
            hasLowStorage = true
            print("âš ï¸ Not enough storage to start recording")
            return
        }
        hasLowStorage = false


        self.selectedQuality = quality

        self.modelContext = modelContext
        
        do {
            // Create new recording session
            let session = RecordingSession(title: title)
            self.currentSession = session
            modelContext.insert(session)
            
            // Setup audio engine for recording
            try setupAudioEngine()
            
            // Start the audio engine
            try audioEngine.start()
            
            // Update state
            isRecording = true
            recordingDuration = 0
            currentSegmentStartTime = 0
            
            // Start timers
            startTimers()
            
            print("Recording started successfully")
            
        } catch {
            print("Failed to start recording: \(error)")
            isRecording = false
        }
    }
    
    /// Stop the current recording session
    func stopRecording() {
        guard isRecording else { return }
        
        // Stop audio engine
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        
        // Stop timers
        stopTimers()
        
        // Finalize current segment
        finalizeCurrentSegment()
        
        // Complete the session
        currentSession?.completeSession()
        
        // Save context
        try? modelContext?.save()
        
        // Reset state
        isRecording = false
        currentSession = nil
        recordingDuration = 0
        audioLevel = 0.0
        
        print("Recording stopped successfully")
    }
    /// Setup AVAudioEngine for recording with real-time processing
    private func setupAudioEngine() throws {
        let inputNode = audioEngine.inputNode
        let fileSettings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 44100.0,
            AVNumberOfChannelsKey: 1,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false
        ]


        //print("ðŸŽ› Mic format: \(recordingFormat.sampleRate) Hz, \(recordingFormat.channelCount) channels")

        
        // Create audio file URL for current segment
        let segmentURL = createSegmentFileURL()
        
        // Create audio file for writing
        audioFile = try AVAudioFile(forWriting: segmentURL, settings: fileSettings)

        let tapFormat = inputNode.outputFormat(forBus: 0)

        // Install tap for real-time audio processing
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: tapFormat) { [weak self] buffer, time in
            try? self?.audioFile?.write(from: buffer)
            self?.updateAudioLevel(from: buffer)
        }

    }
    
    /// Create unique file URL for audio segment
    private func createSegmentFileURL() -> URL {
        let documentsPath = FileManager.default.urls(for: .documentDirectory,
                                                   in: .userDomainMask).first!
        let fileName = "segment_\(UUID().uuidString).wav"
        return documentsPath.appendingPathComponent(fileName)
    }
    
    /// Update audio level for real-time visualization
    private func updateAudioLevel(from buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData?[0] else { return }
        
        let frameLength = Int(buffer.frameLength)
        guard frameLength > 0 else { return }  // Add this check
        
        var sum: Float = 0.0
        
        for i in 0..<frameLength {
            sum += channelData[i] * channelData[i]
        }
        
        let rms = sqrt(sum / Float(frameLength))
        
        // Fix NaN values
        let safeRMS = rms.isNaN || rms.isInfinite ? 0.0 : rms
        
        DispatchQueue.main.async {
            self.audioLevel = safeRMS
        }
    }
}

// MARK: - Timer Management
extension RecordingViewModel {
    /// Start recording and segment timers
    private func startTimers() {
        // Timer for updating recording duration (every 0.1 seconds)
        recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            self?.recordingDuration += 0.1
        }
        
        // Timer for creating new segments
        segmentTimer = Timer.scheduledTimer(withTimeInterval: segmentDuration, repeats: true) { [weak self] _ in
            self?.createNewSegment()
        }
        
        
        print("ðŸ•’ Segment timer started with duration: \(segmentDuration) seconds")

        
    }
    
    /// Stop all timers
    private func stopTimers() {
        recordingTimer?.invalidate()
        segmentTimer?.invalidate()
        recordingTimer = nil
        segmentTimer = nil
    }
    
    // In createNewSegment method, add logging:
    private func createNewSegment() {
        print("ðŸ”¥ createNewSegment called at \(recordingDuration)s")
        
        // Finalize current segment
        print("ðŸ”¥ About to finalize current segment")
        finalizeCurrentSegment()
        print("ðŸ”¥ Finished finalizing current segment")
        
        // Start new segment
        currentSegmentStartTime = recordingDuration
        print("ðŸ”¥ About to setup new audio engine")
        
        // Setup new audio file for next segment
        do {
            let segmentURL = createSegmentFileURL()
            let inputNode = audioEngine.inputNode
            let settings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 44100.0,
                AVNumberOfChannelsKey: 1,
                AVLinearPCMBitDepthKey: 16,
                AVLinearPCMIsFloatKey: false,
                AVLinearPCMIsBigEndianKey: false
            ]

            // Create new audio file
            audioFile = try AVAudioFile(forWriting: segmentURL,
                                        settings: [
                                            AVFormatIDKey: kAudioFormatLinearPCM,
                                            AVSampleRateKey: selectedQuality.sampleRate,
                                            AVLinearPCMBitDepthKey: selectedQuality.bitDepth,
                                            AVNumberOfChannelsKey: 1,
                                            AVLinearPCMIsFloatKey: false,
                                            AVLinearPCMIsBigEndianKey: false
                                        ]
)
            print("ðŸ”¥ Successfully created new audio file: \(segmentURL.lastPathComponent)")
            
        } catch {
            print("ðŸ”¥ FAILED to create new audio file: \(error)")
        }
    }
    
    /// Finalize the current audio segment and save to database
    private func finalizeCurrentSegment() {
        guard let audioFile = audioFile,
              let session = currentSession,
              let modelContext = modelContext else { return }
        
        // Get file path relative to Documents directory
        let fileName = audioFile.url.lastPathComponent
        
        // Create audio segment
        let segment = AudioSegment(
            audioFilePath: fileName,
            startTime: currentSegmentStartTime,
            duration: min(segmentDuration, recordingDuration - currentSegmentStartTime)
        )
        
        // Set up relationships
        segment.session = session
        session.segments.append(segment)
        
        // Create pending transcription
        let transcription = Transcription()
        segment.transcription = transcription
        
        // Save to database
        modelContext.insert(segment)
        modelContext.insert(transcription)
        
        transcriptionService.queueForTranscription(segment, modelContext: modelContext)

        print("Created segment: \(fileName)")
        
        
    }
}

// MARK: - Simple Interruption Handling
extension RecordingViewModel {
    
    /// Setup basic audio interruption observer
    private func setupAudioSessionObservers() {
        print("ðŸ”§ Setting up audio interruption observer")

        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleRouteChange),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioInterruption),
            name: AVAudioSession.interruptionNotification,
            object: nil
        )

    }
    
    @objc private func handleRouteChange(_ notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
            return
        }
        
        switch reason {
        case .oldDeviceUnavailable:
            print("ðŸŽ§ Headphones unplugged or Bluetooth disconnected")
            if isRecording {
                audioEngine.pause()
                try? audioEngine.start()  // Try to resume
                print("âœ… Audio engine restarted after route change")
            }
            
        default:
            break
        }
    }

    
    @objc private func handleAudioInterruption(_ notification: Notification) {
        print("ðŸ”§ INTERRUPTION NOTIFICATION RECEIVED!")  // Add this line
        
        guard let userInfo = notification.userInfo,
              let interruptionType = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt else {
            print("ðŸ”§ No userInfo or interruption type")  // Add this line
            return
        }
        
        print("ðŸ”§ Interruption type: \(interruptionType)")  // Add this line

        switch AVAudioSession.InterruptionType(rawValue: interruptionType) {
        case .began:
            handleInterruptionBegan()
            
        case .ended:
            let options = userInfo[AVAudioSessionInterruptionOptionKey] as? UInt ?? 0
            let shouldResume = (options & AVAudioSession.InterruptionOptions.shouldResume.rawValue) != 0
            handleInterruptionEnded(shouldResume: shouldResume)
            
        default:
            break
        }
    }
    
    private func handleInterruptionBegan() {
        print("ðŸŽµ Audio interruption began (call, Siri, etc.)")
        
        if isRecording {
            // Simple approach: just pause the engine
            audioEngine.pause()
            print("ðŸŽµ Recording paused")
        }
    }
    
    private func handleInterruptionEnded(shouldResume: Bool) {
        print("ðŸŽµ Audio interruption ended - shouldResume: \(shouldResume)")
        
        if isRecording && shouldResume {
            do {
                // Try to resume
                try audioEngine.start()
                print("ðŸŽµ Recording resumed")
                
            } catch {
                print("ðŸŽµ Failed to resume: \(error)")
                // If resume fails, just continue - don't crash
            }
        }
    }
    @objc private func handleAppWillResignActive() {
        print("ðŸ“± App moving to background")
        if isRecording {
            try? AVAudioSession.sharedInstance().setActive(true)
            print("âœ… AVAudioSession kept active in background")
        }
    }

    @objc private func handleAppDidBecomeActive() {
        print("ðŸ“± App back to foreground")
    }

}
